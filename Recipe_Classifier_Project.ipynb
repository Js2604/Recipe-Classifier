{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Recipe Classifier Project",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Js2604/Recipe-Classifier/blob/main/Recipe_Classifier_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmqnR4eNZKeE"
      },
      "source": [
        "# Recipe Classfier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zaro5cw0ZSSY"
      },
      "source": [
        "Goal: Use ingredients to determine what nationality a recipe is from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXxhVeszZbs4"
      },
      "source": [
        "Import packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxtwuWtVrNtn"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osdmXpPYBc9P"
      },
      "source": [
        "!pip install jellyfish\n",
        "import jellyfish"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgzNgD1OZggl"
      },
      "source": [
        "Read training data from train.json; contains a list of 33000 recipes and ingredient lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6i-M5X1rzYw"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "train = pd.read_json(\"train.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hYk5-IXZwU0"
      },
      "source": [
        "Preprocess data, removing misspelt or uncommon ingredients to reduce training time and overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrjs3Kww7GyJ"
      },
      "source": [
        "s = {}\n",
        "for row in train['ingredients']:\n",
        "  for ingredient in row:\n",
        "    if not ingredient in s:\n",
        "      s[ingredient] = 0;\n",
        "    s[ingredient] += 1;\n",
        "\n",
        "import collections\n",
        "#od = [k for k, v in sorted(s.items(), key=lambda item: item[1], reverse=True)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs3WSWRSZ9Mg"
      },
      "source": [
        "View the ten most common ingredients. Looks reasonable. It looks like preprocessing has succeeded!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2022E60-yhmy"
      },
      "source": [
        "od = [k for k, v in sorted(s.items(), key=lambda item: item[1], reverse=True)]\n",
        "od = od[:5000]\n",
        "pop = [(k, v) for k, v in sorted(s.items(), key=lambda item: item[1], reverse=True)]\n",
        "pop[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr7a1xQDynl1"
      },
      "source": [
        "l1, l2 = zip(*pop)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 22})\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "numnum = 20\n",
        "x = list(l1[:numnum])\n",
        "energy = list(l2[:numnum])\n",
        "\n",
        "x_pos = [i for i, _ in enumerate(x)]\n",
        "\n",
        "plt.bar(x_pos, energy, color='pink')\n",
        "plt.xlabel(\"Ingredient\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Frequency of ingredients across training data\")\n",
        "#plt.xticks()\n",
        "plt.xticks(x_pos, x, rotation=-90)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTgBtdkaaNob"
      },
      "source": [
        "Group similar ingredients together based on simple substring comparison to reduce number of possible ingredients. Examples of groupings are printed. \n",
        "\n",
        "Format: grouping | original ingredient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anvS2PlcwaFg"
      },
      "source": [
        "X = []\n",
        "s = od\n",
        "for row in train['ingredients']:\n",
        "  temp = [0] * len(s)\n",
        "  for ingredient in row:\n",
        "    if ingredient in s:\n",
        "      temp[s.index(ingredient)] = 1\n",
        "    else:\n",
        "      for cur_ing in s:\n",
        "        if (\" \" + cur_ing) in ingredient and (\" \" + cur_ing + \" \") not in ingredient:\n",
        "          print(cur_ing, \"|\", ingredient)\n",
        "          temp[s.index(cur_ing)] = 1\n",
        "          break\n",
        "  X.append(temp)\n",
        "  X\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWQs1bCOuAI-"
      },
      "source": [
        "cuisines = []\n",
        "for cuisine in train['cuisine']:\n",
        "    if not cuisine in cuisines:\n",
        "      cuisines.append(cuisine);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeZaohVJypR8"
      },
      "source": [
        "y = [cuisines.index(cuisine) for cuisine in train['cuisine']]\n",
        "z = 30000\n",
        "x_test = X[z:]\n",
        "x_train = X[:z]\n",
        "y_test = y[z:]\n",
        "y_train = y[:z]\n",
        "\n",
        "y_train_one = np.array(to_categorical(y_train))\n",
        "y_test_one = np.array(to_categorical(y_test))\n",
        "\n",
        "x_train_one = np.array([np.transpose(np.array(x)) for x in x_train])\n",
        "x_test_one = np.array([np.transpose(np.array(x)) for x in x_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrFyit7xa2-M"
      },
      "source": [
        "Training neural network with cleaned data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23hU5zlftlg-"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras import regularizers\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Dense(units=100, input_shape=(len(s), )))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Dense(units=100, input_shape=(len(s), )))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Dense(units=20, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "               optimizer='nadam',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train_one, y_train_one, epochs=15, batch_size=2200, shuffle=True)\n",
        "model\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTy7XGmAbRyy"
      },
      "source": [
        "The model acheived an accuracy of .777"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l415U06G_sDZ"
      },
      "source": [
        "print(model.evaluate(x_test_one, y_test_one))\n",
        "model.metrics_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKkOejHN2LrT"
      },
      "source": [
        "def predict(ingredients):\n",
        "  temp = [0] * len(s)\n",
        "  for ingredient in ingredients:\n",
        "    if ingredient in s:\n",
        "      temp[s.index(ingredient)] = 1\n",
        "    else:\n",
        "      for cur_ing in s:\n",
        "        if (\" \" + cur_ing) in ingredient and (\" \" + cur_ing + \" \") not in ingredient:\n",
        "          temp[s.index(cur_ing)] = 1\n",
        "          break\n",
        "  pred = model.predict_on_batch(np.array([np.transpose(np.array(temp))]))\n",
        "  return cuisines[(np.where(pred[0] == max(pred[0]))[0][0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvOBv5rVa8PP"
      },
      "source": [
        "Test predictions on recipe with ['rice', 'beef', 'soy sauce', 'broccoli', 'salt'] ingredients. The model predicts this is a chinese cuisine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18Wo9BXA5CBR"
      },
      "source": [
        "ing = ['rice', 'beef', 'soy sauce', 'broccoli', 'salt']\n",
        "print(\"ingredients:\", ing)\n",
        "print(\"prediction:\", predict(ing))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H29Rx3Q-bbaL"
      },
      "source": [
        "Taking a look at predictions on the testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm6Htpey0J2u"
      },
      "source": [
        "test_tbl = pd.read_json(\"test.json\")\n",
        "test_tbl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J5AKce0tWKD"
      },
      "source": [
        "write = []\n",
        "for index, row in test_tbl.iterrows():\n",
        "    write.append([str(row['id']), predict(row['ingredients'])])\n",
        "  \n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQxjY0-S61LC"
      },
      "source": [
        "print(write)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26uUhmn2bjZx"
      },
      "source": [
        "### Potential improvements\n",
        "\n",
        "*   Additional ingredient simplification to remove uncommon ingredients (ie \"Kraft Extra Fancy American Cheese\" -> \"American Cheese\")\n",
        "*   Reduce amount of wasted data by adopting different forms of data cleaning\n",
        "*   Further parameter tuning\n",
        "\n"
      ]
    }
  ]
}